{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of Copy of P43405_V1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aboagyeso/v1_code/blob/master/Copy_of_Copy_of_Copy_of_Copy_of_P43405_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_QFqo42aiX",
        "colab_type": "code",
        "outputId": "8b906f6b-6d56-4f54-f8b8-31c48f174a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Embedding, Conv1D, MaxPooling1D, GRU\n",
        "from keras import regularizers\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import LSTM\n",
        "import numpy\n",
        "import csv\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import random \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "maxlen = 100\n",
        "batch_size = 128\n",
        "\n",
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_training/v1/P43405.csv\", delimiter=\",\")\n",
        "#X_train = dataset.iloc[:,0:1].values\n",
        "#y_train = dataset.iloc[:,1:2].values\n",
        "X_train = dataset[['smiles']].values\n",
        "y_train = dataset[['pAc']].values\n",
        "\n",
        "for p in range (X_train.shape[0]):\n",
        "  s = X_train[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_train[p,0] = s\n",
        "X_train = X_train[:,0]  \n",
        "#y_train = y_train[:,0]\n",
        "X_train = X_train.tolist()\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=100)\n",
        "print(X_train)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 1 5 5]\n",
            " [0 0 0 ... 1 4 5]\n",
            " [0 0 0 ... 1 4 5]\n",
            " ...\n",
            " [0 0 0 ... 2 2 4]\n",
            " [0 0 0 ... 1 1 4]\n",
            " [0 0 0 ... 5 2 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAGViFDk5r1j",
        "colab_type": "code",
        "outputId": "d71542c1-14da-480b-e347-7ecbb1abe738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_validation/smilesP43405.csv\", delimiter=\",\")\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "X_test = dataset[['smiles']].values\n",
        "y_test = dataset[['pAc']].values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "for p in range (X_test.shape[0]):\n",
        "  s = X_test[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_test[p,0] = s\n",
        "X_test = X_test[:,0]  \n",
        "#y_test = y_test[:,0]\n",
        "X_test = X_test.tolist()\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test, maxlen=100)\n",
        "#print(X_test)\n",
        "#print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(100, 128, input_length=100))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(0.001))\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=20)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 20:50:06.336480 140258084849536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0726 20:50:06.358541 140258084849536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 20:50:06.362677 140258084849536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0726 20:50:06.702471 140258084849536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 20:50:06.949749 140258084849536 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0726 20:50:07.730648 140258084849536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0726 20:50:07.882170 140258084849536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10660/10660 [==============================] - 33s 3ms/step - loss: 6.6317\n",
            "Epoch 2/20\n",
            "10660/10660 [==============================] - 32s 3ms/step - loss: 1.3649\n",
            "Epoch 3/20\n",
            "10660/10660 [==============================] - 40s 4ms/step - loss: 1.3568\n",
            "Epoch 4/20\n",
            "10660/10660 [==============================] - 63s 6ms/step - loss: 1.3536\n",
            "Epoch 5/20\n",
            "10660/10660 [==============================] - 75s 7ms/step - loss: 1.3514\n",
            "Epoch 6/20\n",
            "10660/10660 [==============================] - 122s 11ms/step - loss: 1.3484\n",
            "Epoch 7/20\n",
            "10660/10660 [==============================] - 172s 16ms/step - loss: 1.3487\n",
            "Epoch 8/20\n",
            "10660/10660 [==============================] - 205s 19ms/step - loss: 1.3424\n",
            "Epoch 9/20\n",
            "10660/10660 [==============================] - 206s 19ms/step - loss: 1.3333\n",
            "Epoch 10/20\n",
            "10660/10660 [==============================] - 206s 19ms/step - loss: 1.3243\n",
            "Epoch 11/20\n",
            "10660/10660 [==============================] - 206s 19ms/step - loss: 1.1903\n",
            "Epoch 12/20\n",
            "10660/10660 [==============================] - 207s 19ms/step - loss: 1.1042\n",
            "Epoch 13/20\n",
            "10660/10660 [==============================] - 206s 19ms/step - loss: 1.0608\n",
            "Epoch 14/20\n",
            "10660/10660 [==============================] - 206s 19ms/step - loss: 1.0569\n",
            "Epoch 15/20\n",
            "10660/10660 [==============================] - 206s 19ms/step - loss: 1.0389\n",
            "Epoch 16/20\n",
            "10660/10660 [==============================] - 178s 17ms/step - loss: 1.0305\n",
            "Epoch 17/20\n",
            "10660/10660 [==============================] - 152s 14ms/step - loss: 1.0311\n",
            "Epoch 18/20\n",
            "10660/10660 [==============================] - 134s 13ms/step - loss: 1.0269\n",
            "Epoch 19/20\n",
            "10660/10660 [==============================] - 98s 9ms/step - loss: 1.0443\n",
            "Epoch 20/20\n",
            "10660/10660 [==============================] - 69s 6ms/step - loss: 1.0216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f901f3bfeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QojRQg6i4Kfa",
        "colab_type": "code",
        "outputId": "526bbdc6-b5f4-4783-d48f-fc8450369d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test,\n",
        "                            batch_size=128)\n",
        "print('Test score:', score)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2_score = r2_score(y_test, predictions)\n",
        "\n",
        "print(str(mae)+\"\\t\"+str(mse)+\"\\t\"+str(r2_score))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "219/219 [==============================] - 1s 3ms/step\n",
            "Test score: 0.993962356761166\n",
            "0.8004904162901904\t0.993962222724031\t0.28247522203064723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WYlIvMH4KTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zPbT3cy4J60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}